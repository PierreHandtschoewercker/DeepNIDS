{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d6513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from netml.pparser.parser import PCAP\n",
    "import pprint\n",
    "from scapy.all import *\n",
    "from scapy.layers.inet import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bbd066",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"/code/2.Malwares/\"\n",
    "targetFile = \"Zeus.pcap\"\n",
    "destination = dataDir + \"out\"\n",
    "tsharkPath=\"/usr/bin/tshark\"\n",
    "packetSizeInBytes = 100\n",
    "packetsPerFlow = 2\n",
    "tfrecorsFolder = dataDir + 'tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c9f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [\"Benign\",\"Malware\"]\n",
    "listofProcessedFiles = []\n",
    "training_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd24525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabelForFile(filename):\n",
    "    filename.replace('.pcap','')\n",
    "    if filename.find('-') != -1:\n",
    "        filename = filename.split('-')[0]\n",
    "    for index,processedFile in enumerate(listofProcessedFiles):\n",
    "        if processedFile == filename:\n",
    "            return index\n",
    "    listofProcessedFiles.append(filename)\n",
    "    return len(listofProcessedFiles)\n",
    "    \n",
    "#pprint.pprint(listofProcessedFiles)\n",
    "#label = getLabelForFile('tes-test')\n",
    "#print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):# peut-être un tableau\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()  # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features dictionary.\n",
    "def packet_example(packetArray, label):\n",
    "    feature = {\n",
    "        'label': _int64_feature(label),\n",
    "        'packet1': _bytes_feature(packetArray[0]),\n",
    "        'packet2': _bytes_feature(packetArray[1]),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def processPackets(packets)\n",
    "    newFlow = []\n",
    "    for i,packet in enumerate(packets):\n",
    "        packetHex = linehexdump(packet.payload,onlyhex=1,dump=True) # dump packet to hex\n",
    "        packetHexnoSpace = packetHex.replace(' ','').lower() #to hex\n",
    "        packetBytes = bytes.fromhex(packetHexnoSpace) # to bytestring\n",
    "        if len(packetBytes) < packetSizeInBytes: # ajuster les packets à une taille de 100 bytes \n",
    "            packetPadded = packetBytes.ljust(packetSizeInBytes,b'\\0') #padding\n",
    "        else:\n",
    "            packetPadded = packetBytes[:packetSizeInBytes] # couper les paquet trop grand\n",
    "        if i >= packetsPerFlow:\n",
    "            #print('je break!')\n",
    "            break\n",
    "        newFlow.append(packetPadded)\n",
    "    return newFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda772df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for cat in cats: # pour chaqye dossier Benign, Malware\n",
    "    path = os.path.join(dataDir,cat)\n",
    "    for filePcap in os.listdir(path): #parcours les fichiers pour chaque dossier\n",
    "        pprint.pprint(path)\n",
    "        pprint.pprint(filePcap)\n",
    "\n",
    "        parsedPcap = PCAP(\n",
    "        os.path.join(path,filePcap),\n",
    "        flow_ptks_thres=packetsPerFlow,\n",
    "        )\n",
    "        parsedPcap.pcap2flows(interval=1000)\n",
    "        for flow in tqdm(parsedPcap.flows): #(val,182.168.1.15,,)(<Ether\n",
    "            flow = flow[1:] # retirer le premier élément car inutile\n",
    "            for packets in flow:\n",
    "                tfrecordsFileName = filePcap.replace('.pcap','.tfrecords')\n",
    "                with tf.io.TFRecordWriter(tfrecorsFolder + os.sep +tfrecordsFileName) as writer:\n",
    "                     tf_example = packet_example(processPackets(packets), getLabelForFile(filePcap))\n",
    "                     writer.write(tf_example.SerializeToString())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TODO : convertir hexdump srting to bytestring (https://www.delftstack.com/howto/python/python-convert-hex-to-byte/)\n",
    "        - ensure only the two first packet are processed ok\n",
    "        - implement padding ok\n",
    "        - label each flow \n",
    "        - put everything in pickles\n",
    "        - tweak to treat whole dataset not juste one pcap file\n",
    "\n",
    "        [[packet 1,\n",
    "        packet 2],\n",
    "        label]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba490974",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}